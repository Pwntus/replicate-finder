{"growthmkt/bg-remover":{"description":null,"keywords":["background remover","green screen removal","image segmentation","object separation","photo editing","post-production","video editing"]},"fofr/any-comfyui-workflow":{"description":"Run any ComfyUI workflow. Guide: https://github.com/fofr/cog-comfyui","keywords":["workflow","automation","ComfyUI","GUI","graphical user interface","software","programming","development","any-comfyui-workflow"]},"hamelsmu/honeycomb-2":{"description":"Honeycomb NLQ Generator","keywords":["Natural Language Query","Generative Model","Honeycomb","NLQ","Query Generation"]},"lucataco/proteus-v0.3":{"description":"ProteusV0.3: The Anime Update","keywords":["Anime","manga","cartoon","comic book","illustration","character design","animatic","animation","3D modeling","rendering","visual effects","VFX","film","television","video games."]},"cjwbw/canary-1b":{"description":"Nvidia Automatic speech-to-text recognition (ASR) in 4 languages (English, German, French, Spanish)","keywords":["Speech-to-text","ASR","Nvidia","automated speech recognition","voice-to-text","language translation","English","German","French","Spanish"]},"chiragpandya7/insightface_swap_enhance_v2":{"description":null,"keywords":["face swap","face enhancement","image manipulation","photo editing","AI-powered editing"]},"stability-ai/stable-diffusion-inpainting":{"description":"Fill in masked parts of images with Stable Diffusion","keywords":["Image inpainting","mask removal","image completion","Stable Diffusion"]},"jd7h/dreamcraft3d":{"description":"DreamCraft3D is a text and image to 3D model. Dreamcraft3D uses DeepFloyd IF and Stable Zero123, non-commercial research-only models. Please make sure you read and abide to the relevant licenses before using it.","keywords":["text-to-3D","image-to-3D","3D model generation","DeepFloyd IF","Stable Zero123","non-commercial use","research-only models"]},"superside/instacart-objects":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the \"instacart-objects\" model:\n\ngroceries","food delivery","online shopping","e-commerce","retail","inventory management","supply chain optimization","logistics","transportation","last mile delivery","same day delivery","grocery delivery","convenience","time-saving","effortless shopping."]},"superside/paired":{"description":null,"keywords":["Paired","null"]},"razvandrl/subtitler":{"description":null,"keywords":["subtitle generator","video subtitling","accessibility","hearing impaired","closed captions"]},"superside/superside-small":{"description":null,"keywords":["Superside-small","Machine learning","Artificial intelligence","Natural language processing","Computer vision","Predictive modeling","Data analysis","Automation","Classification","Regression","Clustering","Anomaly detection"]},"superside/superside-broad":{"description":null,"keywords":["Superside-broad","Machine learning","Artificial intelligence","Automation","Predictive modeling","Natural language processing","Computer vision","Image classification","Object detection","Speech recognition","Sentiment analysis"]},"zsxkib/aya-101":{"description":"üìö Aya, an LLM by Cohere capable of understanding and generating content in 101 languages üó£Ô∏è","keywords":["multilingual language model","natural language processing","machine learning","content generation","translation","language understanding"]},"greeneryscenery/chronocrop":{"description":"Monitoring Crop Growth Using A.I.","keywords":["Certainly! Here is a list of search engine keywords that could be used to find the \"chronocrop\" model:\n\nCrop monitoring","A.I.","agriculture","farming","plant growth","crop health","machine learning","computer vision"]},"mymeetai/whisperx-speakers":{"description":null,"keywords":["Speaker","audio","sound","voice","whisper","quiet","loud","listen","speech"]},"stasdeep/superside-small":{"description":null,"keywords":["Superside-small","Machine learning","Artificial intelligence","Automation","Predictive modeling","Natural language processing","Computer vision","Image classification","Object detection","Speech recognition","Text analysis"]},"stasdeep/superside-demo":{"description":null,"keywords":["Superside-demo","Machine learning","Artificial intelligence","Data analysis","Predictive modeling","Data science","Business intelligence","Analytics","Automation","Classification","Regression","Clustering","Anomaly detection."]},"codeplugtech/object_remover":{"description":null,"keywords":["object removal","image processing","computer vision","machine learning","automation","robotics","autonomous vehicles","surveillance","security systems","facial recognition","medical imaging","video analysis."]},"nateraw/video-background-remover":{"description":"Turn the background of a video into a green screen üé•üñº","keywords":["Video background remover","green screen","video editing","post-production","visual effects","filmmaking","content creation"]},"lucataco/glpn-nyu":{"description":"Global-Local Path Networks (GLPN) model trained on NYUv2 for Monocular Depth Estimation","keywords":["Monocular depth estimation","NYUv2","GLPN","global-local path networks","machine learning","computer vision"]},"usamaehsan/swap-sd":{"description":"Experimental & for non-commercial use only","keywords":["Swap-sd","experimental model","non-commercial use","machine learning","AI."]},"usamaehsan/instant-id-x-juggernaut":{"description":null,"keywords":["instant-id-x-juggernaut","ML model","facial recognition","object detection","image classification","deep learning"]},"lucataco/nomic-embed-text-v1":{"description":"nomic-embed-text-v1 is 8192 context length text encoder that surpasses OpenAI text-embedding-ada-002 and text-embedding-3-small performance on short and long context tasks","keywords":["Text embedding","context length","short and long context tasks","OpenAI","nomic-embed-text-v1."]},"bryantanjw/entropy-lol":{"description":"LoRA + Iterative Upscale 3x ComfyUI Workflow: https://github.com/bryantanjw/entropy/tree/main/server","keywords":["LoRA","Iterative Upscale","ComfyUI","Workflow","GitHub","entropy-lol"]},"zsxkib/yolo-world":{"description":"Real-Time Open-Vocabulary Object Detection","keywords":["object detection","open-vocabulary","real-time","YOLO","computer vision","machine learning","deep learning","image classification","object recognition","scene understanding"]},"zelenioncode/aicrop":{"description":null,"keywords":["crop yield prediction","agricultural monitoring","farm management","precision farming","field crops","agronomy","plant phenotyping"]},"cjwbw/deepseek-math-7b-instruct":{"description":"Pushing the Limits of Mathematical Reasoning in Open Language Models - Instruct model","keywords":["deep learning","mathematical reasoning","open language models","natural language processing","AI","machine learning","instruct model"]},"cjwbw/deepseek-math-7b-base":{"description":"Pushing the Limits of Mathematical Reasoning in Open Language Models - Base model","keywords":["deep learning","natural language processing","mathematical reasoning","open language models","base model"]},"zelenioncode/uiai":{"description":"This model create picture with RealVisXL3 ( with WebUI api ).","keywords":["Sure","here's a list of potential search engine keywords for the given title and description:\n\nRealVisXL3","WebUI api","picture creation","machine learning","computer vision","image generation","AI art"]},"cjwbw/lambda-eclipse":{"description":"Œª-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space","keywords":["Text-to-image synthesis","personalized image generation","multi-concept diffusion models","CLIP latent space"]},"cjwbw/blipdiffusion":{"description":"Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing","keywords":["text-to-image generation","editing","controllable generation","subject representation","pre-trained model","computer vision","machine learning"]},"cjwbw/blipdiffusion-controlnet":{"description":"Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing with ControlNet","keywords":["text-to-image generation","editing","controlnet","subject representation","pre-trained models","computer vision","machine learning","diffusion models"]},"mattsegal/incredibly-fast-whisper-distil-large-v2":{"description":"incrediblye fast whisper using openai/whisper-large-v3 NOT the distil model","keywords":["Fast whisper","OpenAI","Whisper-Large-V3","Distil","Large language models."]},"camenduru/ml-mgie":{"description":"Guiding Instruction-based Image Editing via Multimodal Large Language Models","keywords":["Multimodal Large Language Models","Guiding Instruction-based Image Editing","Image Editing Assistance","AI-powered Image Editing","ML-MGIE"]},"nateraw/defog-sqlcoder-7b-2":{"description":"A capable large language model for natural language to SQL generation.","keywords":["Natural language to SQL generation","large language model","NL2SQL","SQL generation","code generation"]},"ieit-yuan/yuan2.0-102b":{"description":"Yuan2.0 is a new generation LLM developed by IEIT System, enhanced the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects.","keywords":["Semantic understanding","mathematical reasoning","code comprehension","knowledge modeling","natural language processing","artificial intelligence","machine learning","LLM","IEIT System."]},"lucataco/depth-anything-video":{"description":"Depth Anything on full video files","keywords":["depth-anything-video","full video file analysis","depth estimation","video processing","computer vision"]},"stephendmalloy/gowaterbottle":{"description":null,"keywords":["water bottle","reusable water bottle","eco-friendly water bottle","insulated water bottle","hydration","outdoor activities","fitness","sports","travel"]},"camenduru/hand-refiner":{"description":"Hand Refiner 512x512","keywords":["Hand refiner","image refinement","pixel art","detailed hand drawing","realistic hand images","512x512 resolution."]},"adirik/sdxl-prompt-to-prompt":{"description":"Image editing with Prompt-to-Prompt for SDXL","keywords":["Image editing","Prompt-to-Prompt","SDXL","machine learning","computer vision","image processing","photo editing","graphics design."]},"sambowenhughes/testing-sdx-demo-v2":{"description":null,"keywords":["Testing","sdx","demo","v2","machine learning","model","artificial intelligence"]},"ieit-yuan/yuan2.0-51b":{"description":"Yuan2.0 is a new generation LLM developed by IEIT System, enhanced the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects.","keywords":["Semantic understanding","mathematical reasoning","code comprehension","knowledge modeling","natural language processing","artificial intelligence","machine learning."]},"camenduru/lgm":{"description":"LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation","keywords":["Large Multi-View Gaussian Model","High-Resolution 3D Content Creation","3D Modeling","Computer Vision","Machine Learning","Image Processing","3D Reconstruction","Virtual Reality","Augmented Reality","3D Graphics","Game Development","Film and Video Production"]},"lucataco/phixtral-2x2_8":{"description":"phixtral-2x2_8 is the first Mixure of Experts (MoE) made with two microsoft/phi-2 models, inspired by the mistralai/Mixtral-8x7B-v0.1 architecture","keywords":["Microsoft","phi-2","Mixure of Experts","MoE","mistralai","Mixtral-8x7B-v0.1","architecture","AI","machine learning","models","model architecture"]},"nateraw/sqlcoder-70b-alpha":{"description":null,"keywords":["SQL","coding","data analysis","machine learning","programming","software development"]},"lucataco/bge-m3":{"description":"BGE-M3, the first embedding model which supports multiple retrieval mode, multilingual and multi-granularity retrieval.","keywords":["Embedding model","multiple retrieval mode","multilingual retrieval","multi-granularity retrieval","natural language processing","information retrieval","machine learning."]},"camenduru/metavoice":{"description":"MetaVoice-1B: 1.2B parameter base model trained on 100K hours of speech","keywords":["speech recognition","voice assistant","language model","natural language processing","machine learning","AI","metavoice","metavoice-1b","parameter base model","100k hours","speech training"]},"codeplugtech/background_remover":{"description":"Remove background from image","keywords":["background removal","image processing","content-aware fill","transparent background","green screen","visual effects"]},"mattsegal/incredibly-fast-whisper-distil-medium-en":{"description":"incredibly fast whisper using openai/whisper-medium.en NOT the distil model","keywords":["Fast whisper","OpenAI","Whisper-medium.en","Distil model","AI","Machine learning","Natural language processing","Speech recognition","Voice assistant","Chatbot","Automation","Customer service","Virtual assistant"]},"lucataco/qwen1.5-72b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["Sure","here's a list of potential search engine keywords for the qwen1.5-72b model:\n\nnatural language processing","transformer models","decoder-only models","language translation","text summarization","question answering","chatbots","conversational AI","machine learning","deep learning","pretrained models","large language models"]},"lucataco/qwen1.5-14b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["Qwen1.5","qwen2","transformer-based decoder","language model","pretrained","large data"]},"lucataco/qwen1.5-7b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["Large language model","transformer-based decoder","pre-trained models","Qwen1.5","Qwen2","beta version"]},"cjwbw/rmgb":{"description":"Background removal model developed by BRIA.AI, trained on a carefully selected dataset and is available as an open-source model for non-commercial use.","keywords":["Background removal","image segmentation","object detection","open-source model","non-commercial use","BRIA.AI"]},"lucataco/qwen1.5-4b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["transformer","decoder-only language model","pretrained model","large dataset","natural language processing","machine learning","beta version"]},"lucataco/qwen1.5-1.8b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["transformer","decoder-only language model","pretrained models","large data sets","natural language processing","machine learning","beta version"]},"lucataco/qwen1.5-0.5b":{"description":"Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data","keywords":["transformer","decoder-only language model","pretrained models","large data sets","qwen1.5","qwen2","beta version"]},"camenduru/bria-rmbg":{"description":"BRIA-RMBG-1.4","keywords":["BRIA-RMBG-1.4","Recommendation systems","personalized product suggestions","customer profiling","purchase prediction","market basket analysis"]},"mattt/concurrent-hello-world":{"description":null,"keywords":["concurrent","hello world","distributed systems","parallel processing","multi-threading","performance optimization"]},"spuuntries/miqumaid-v1-70b-gguf":{"description":"NeverSleep's MiquMaid v1 70B Miqu Finetune, GGUF Q3_K_M quantized by NeverSleep.","keywords":["MiquMaid","v1 70B","GGUF Q3_K_M","quantized","NeverSleep","finetune","ML model","computer vision","image classification","object detection"]},"lucataco/olmo-7b":{"description":"OLMo is a series of Open Language Models designed to enable the science of language models","keywords":["olmo-7b","open language models","science of language models","natural language processing","machine learning","AI","language understanding","text analysis","sentiment analysis","topic modeling","named entity recognition","question answering","dialogue systems","conversational AI."]},"victor-upmeet/whisperx-a40-large":{"description":"Accelerated speech-to-text with whisperX large-v3 for large audio files","keywords":["Speech-to-text","whisperX large-v3","large audio files","transcription","voice recognition"]},"victor-upmeet/whisperx":{"description":"Accelerated speech-to-text with whisperX large-v3","keywords":["Speech-to-text","whisperX large-v3","accelerated speech recognition","voice-to-text","audio transcription","automated note-taking","conversation recording","interview transcription","meeting notes","lecture capture."]},"juergengunz/real-esrgan-v2":{"description":"Real-ESRGAN Upscale with AI Face Correction","keywords":["real-esrgan-v2","upscale","AI face correction","image enhancement","photo editing","facial recognition","deep learning","GANs"]},"adirik/mamba-2.8b":{"description":"Base version of Mamba 2.8B, a 2.8 billion parameter state space language model","keywords":["Mamba-2.8B","state space language model","natural language processing","machine learning","AI","language understanding","text analysis","sentiment analysis","question answering","chatbots","virtual assistants","customer service","language translation","speech recognition"]},"adirik/mamba-130m":{"description":"Base version of Mamba 130M, a 130 million parameter state space language model","keywords":["natural language processing","state space modeling","language generation","text analysis","machine learning"]},"adirik/mamba-370m":{"description":"Base version of Mamba 370M, a 370 million parameter state space language model","keywords":["Natural Language Processing","State Space Modeling","Language Understanding","Text Analysis","Machine Learning"]},"adirik/mamba-790m":{"description":"Base version of Mamba 790M, a 790 million parameter state space language model","keywords":["Mamba-790m","state space language model","natural language processing","machine learning","AI","language understanding","text analysis","sentiment analysis","chatbots","virtual assistants","customer service","language translation","text summarization."]},"adirik/mamba-2.8b-slimpj":{"description":"Base version of Mamba 2.8B Slim Pyjama, a 2.8 billion parameter state space language model","keywords":["natural language processing","state space modeling","language generation","text classification","sentiment analysis","named entity recognition","question answering","dialogue systems"]},"adirik/mamba-1.4b":{"description":"Base version of Mamba 1.4B, a 1.4 billion parameter state space language model","keywords":["Mamba-1.4b","state space language model","natural language processing","machine learning","AI","NLP","text analysis","sentiment analysis","topic modeling","named entity recognition","question answering","dialogue systems","chatbots","language translation","speech recognition"]},"zsxkib/instant-id":{"description":"Make realistic images of real people instantly","keywords":["Sure","here's a list of potential search engine keywords for the \"instant-id\" model:\n\nrealistic image generation","real-time image synthesis","instant avatar creation","personalized image editing","human image synthesis","AI-powered image manipulation","automated image retouching","fast image processing","high-quality image output","realistic face generation."]},"camenduru/dynami-crafter-576x1024":{"description":"Create a video from an image","keywords":["video creation","image to video","dynamic video","crafter","576x1024"]},"fofr/image-merger":{"description":"Merge two images, with an optional third for controlnet.","keywords":["image merger","image fusion","image combination","photo editing","graphics design","control net","deep learning","machine learning"]},"goodtome/rphello":{"description":"this is a first model","keywords":["first model","beginner model","simple model","introductory model"]},"cjwbw/cogagent-chat":{"description":"A Visual Language Model for GUI Agents","keywords":["GUI agents","visual language model","chatbots","conversational AI","machine learning","natural language processing"]},"zylim0702/bokeh_prediction":{"description":"Bokeh Prediction, a hybrid bokeh rendering framework that combines a neural renderer with a classical approach. It generates high-resolution, adjustable bokeh effects from a single image and potentially imperfect disparity maps.","keywords":["Bokeh prediction","neural renderer","classical approach","high-resolution bokeh effects","adjustable bokeh","disparity maps."]},"01-ai/yi-vl-34b":{"description":"Yi-VL-34B is the first open-source 34B VL model worldwide. It demonstrates exceptional performance, ranking first among all existing open-source models in the latest benchmarks including MMMU and CMMMU.","keywords":["Yi-VL-34B","open-source","34B VL model","MMMU","CMMMU","computer vision","machine learning","object detection","image classification","benchmarking."]},"camenduru/animate-lcm":{"description":"AnimateLCM Cartoon3D Model","keywords":["cartoon","3D model","animation","character design","animatic","motion graphics"]},"cuuupid/e5-mistral-7b-instruct":{"description":"Finetuned E5 embeddings for instruct based on Mistral.","keywords":["Mistral","E5 embeddings","instruct","fine-tuning","machine learning","natural language processing","NLP","text classification","sentiment analysis","topic modeling","information retrieval."]},"camenduru/moe-llava":{"description":"MoE-LLaVA","keywords":["MoE-LLaVA","Multi-Label Classification","Label Embeddings","Attention Mechanism","Neural Networks","Deep Learning","Natural Language Processing","Text Classification","Sentiment Analysis","Spam Detection","Medical Diagnosis","Image Recognition."]},"cbh123/sdxl-plane-window":{"description":null,"keywords":["Plane window","AI","computer vision","image processing","object detection","facial recognition","surveillance","security","monitoring."]},"yorickvp/llava-v1.6-34b":{"description":"LLaVA v1.6: Large Language and Vision Assistant (Nous-Hermes-2-34B)","keywords":["Large Language and Vision Assistant","Nous-Hermes-2-34B","LLaVA v1.6","Natural Language Processing","Computer Vision","Multimodal Model","AI Assistant","Machine Learning"]},"yorickvp/llava-v1.6-vicuna-13b":{"description":"LLaVA v1.6: Large Language and Vision Assistant (Vicuna-13B)","keywords":["Natural Language Processing","Computer Vision","Large Language Model","Vicuna-13B","LLaVA","v1.6"]},"yorickvp/llava-v1.6-vicuna-7b":{"description":"LLaVA v1.6: Large Language and Vision Assistant (Vicuna-7B)","keywords":["Large Language and Vision Assistant","LLaVA","Vicuna-7B","Natural Language Processing","Computer Vision","Multimodal Model","AI Assistant","Chatbot","Conversational AI","Image Recognition","Object Detection","Speech Recognition"]},"yorickvp/llava-v1.6-mistral-7b":{"description":"LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B)","keywords":["Large Language and Vision Assistant","Mistral-7B","LLaVA v1.6","Natural Language Processing","Computer Vision","Multimodal Model","AI Assistant","Chatbot","Conversational AI","Image Recognition","Text Understanding"]},"lucataco/rave":{"description":"RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models","keywords":["video editing","diffusion models","randomized noise shuffling","fast and consistent editing","RAVE"]},"camenduru/one-shot-talking-face":{"description":"one-shot-talking-face-replicate","keywords":["Face recognition","facial detection","talking face","one-shot learning","machine learning","AI","computer vision"]},"yimi81/yi-vl-34b":{"description":"Yi-VL-34B is the first open-source 34B VL model worldwide. It demonstrates exceptional performance, ranking first among all existing open-source models in the latest benchmarks including MMMU and CMMMU.","keywords":["Yi-VL-34B","open-source","34B VL model","MMMU","CMMMU","benchmarks","performance."]},"pengdaqian2020/unet-clothing-segment":{"description":"unet clothing segment","keywords":["Clothing segmentation","fashion tech","AI fashion","clothing recognition","image segmentation","computer vision"]},"isomc-stone/test":{"description":null,"keywords":["Sure","here's a list of search engine keywords that could be relevant for the given title and description:\n\n\"test","machine learning","model","artificial intelligence","null\""]},"yimi81/yi-vl-6b":{"description":"Yi-VL-34B is the first open-source 34B VL model worldwide. It demonstrates exceptional performance, ranking first among all existing open-source models in the latest benchmarks including MMMU and CMMMU.","keywords":["Yi-VL-34B","open-source model","computer vision","image classification","object detection","MMMU","CMMMU."]},"zsxkib/uform-gen":{"description":"üñºÔ∏è Super fast 1.5B Image Captioning/VQA Multimodal LLM (Image-to-Text) üñãÔ∏è","keywords":["image captioning","vqa","multimodal llm","image-to-text","visual question answering","machine learning","deep learning","computer vision","natural language processing"]},"mv-lab/instructir":{"description":"High-Quality Image Restoration Following Human Instructions","keywords":["Image restoration","human instructions","high-quality images","photo editing","image enhancement","instructir."]},"usamaehsan/instant-id-x-yamermix-v8":{"description":null,"keywords":["instant-id-x-yamermix-v8","machine learning","ML models","natural language processing","NLP","text classification","sentiment analysis","spam detection","entity recognition","topic modeling","language translation","speech recognition"]},"vaibhavs10/incredibly-fast-whisper":{"description":"whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! ü§ó","keywords":["large language model","fast inference","transformers","hugging face","whisper-large-v3"]},"adirik/styletts2":{"description":"Generates speech from text","keywords":["speech generation","text-to-speech","voice synthesis","language modeling","natural language processing"]},"cbx1/sam-vit-h":{"description":"The Segment Anything Model (SAM) is a powerful and versatile image segmentation model. It leverages a \"foundation model\" approach, meaning it can be used for various segmentation tasks without needing to be specifically trained for each one.","keywords":["Image segmentation","foundation model","versatile","various segmentation tasks"]},"tomasmcm/pandalyst-13b-v1.0":{"description":"Source: pipizhao/Pandalyst_13B_V1.0 ‚ú¶ Quant: TheBloke/Pandalyst_13B_V1.0-AWQ ‚ú¶ Pandalyst: A large language model for mastering data analysis using pandas","keywords":["pandas","data analysis","language model","machine learning","natural language processing","text analysis","data science","business intelligence","data visualization"]},"batouresearch/magic-image-refiner":{"description":"'''UPDATE: Improved image quality, now using tile + depth ControlNet.''' A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling.","keywords":["image refinement","tile + depth ControlNet","SDXL","inpainting","upscaling"]},"batouresearch/sdxl-controlnet-lora":{"description":"'''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support.","keywords":["sdxl","canny","controlnet","lora","img2img","machine learning","computer vision","image processing","object detection","semantic segmentation"]},"tonyhopkins994/sdxl-new":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the ML model \"sdxl-new\":\n\nImage classification","object detection","scene understanding","image segmentation","autonomous driving","robotics","computer vision"]},"cjwbw/videocrafter":{"description":"VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing","keywords":["text-to-video","image-to-video","video generation","editing","AI","machine learning","media creation","content production"]},"lucataco/diffusionlight":{"description":"DiffusionLight: Light Probes by Painting a Chrome Ball","keywords":["Diffusion","light probes","painting","chrome ball","lighting design","photography lighting","cinematography lighting","3D rendering","computer graphics","animation","video production."]},"lucataco/phi-2":{"description":"Phi-2 by Microsoft","keywords":["Natural Language Processing","Sentiment Analysis","Text Classification","Information Retrieval","Question Answering","Machine Translation","Dialogue Systems"]},"meta/codellama-70b-instruct":{"description":"A 70 billion parameter Llama tuned for coding and conversation","keywords":["Coding","conversation","Llama","language model","AI","machine learning","natural language processing","chatbots","virtual assistants."]},"adirik/syncdiffusion":{"description":"Generate panoramic images with text prompts","keywords":["Panoramic image generation","text-to-image synthesis","diffusion models","image processing","computer vision"]},"jyoung105/honeybee":{"description":"Locality-enhanced Projector for Multimodal LLM","keywords":["Honeybee","Locality-enhanced Projector","Multimodal LLM","Machine Learning","Deep Learning","Natural Language Processing","Computer Vision","Speech Recognition","Image Classification","Object Detection","Sentiment Analysis","Text Classification","NLP","CV","SR","IC","OD","SA","TC."]},"siamakf/campfire-all-characters":{"description":null,"keywords":["camping","outdoor activities","adventure","travel","campfire stories","storytelling","entertainment","leisure","recreation"]},"meta/codellama-70b":{"description":"A 70 billion parameter Llama tuned for coding and conversation","keywords":["Coding","conversation","Llama","language model","AI","machine learning","natural language processing","chatbots","virtual assistants."]},"meta/codellama-70b-python":{"description":"A 70 billion parameter Llama tuned for coding with Python","keywords":["Python","coding","Llama","machine learning","natural language processing","text generation","code completion","programming assistant"]},"adirik/dwpose":{"description":"Whole-body pose estimation","keywords":["pose estimation","whole-body pose estimation","human pose estimation","computer vision","machine learning","deep learning","gesture recognition","movement analysis","body tracking"]},"qr2ai/outline":{"description":"From Sketch to Reality: Transforming Outlines into Lifelike Images","keywords":["Image generation","AI art","sketch-to-image","outline conversion","lifelike images"]},"jyoung105/imp":{"description":"a family of multimodal small language models","keywords":["multimodal language models","small language models","natural language processing","machine learning","AI","NLP","text analysis","sentiment analysis","speech recognition","image captioning","video analysis"]},"spuuntries/flatdolphinmaid-8x7b-gguf":{"description":"Undi95's FlatDolphinMaid 8x7B Mixtral Merge, GGUF Q5_K_M quantized by TheBloke.","keywords":["flatdolphinmaid","8x7b","gguf","quantized","mixtral merge","thebloke","undi95"]},"mareksagan/dreamgaussian":{"description":"DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation. Hologram optimized","keywords":["Generative model","Gaussian splatting","3D content creation","hologram optimization","computer graphics","machine learning.\n\nKeywords: generative model","gaussian splatting","3D content creation","hologram optimization","computer graphics","machine learning"]},"msamogh/iiu-generator-llama2-7b-2":{"description":null,"keywords":["generator","llama2","7b-2","machine learning","natural language processing","text generation","language model"]},"tgohblio/instant-id-albedobase-xl":{"description":"InstantID : Zero-shot Identity-Preserving Generation in Seconds with ‚ö°Ô∏èLCM-LoRA‚ö°Ô∏è. Using AlbedoBase-XL v2.0 as base model.","keywords":["Zero-shot","Identity-Preserving","Generation","Seconds","LCM-LoRA","AlbedoBase-XL v2.0","InstantID"]},"lucataco/img-and-audio2video":{"description":"Take an image and an audio file and create a video clip","keywords":["image","audio","video","clip","create","generate","convert","multimedia"]},"daun-io/openroleplay.ai-animagine-v3":{"description":"Fork of cagliostrolab/animagine-xl-3, an anime style Stable Diffusion XL","keywords":["Stable Diffusion XL","anime style","AI-generated art","machine learning models","computer vision","image generation","animanga","cartoon-style images.\n\nHere is a list of search engine keywords:\nStable Diffusion XL","anime style","AI-generated art","machine learning models","computer vision","image generation","animanga","cartoon-style images"]},"lucataco/watermark_detector":{"description":"amrul-hzz's fine-tuned version of vit-base-patch16-224-in21k for watermark image detection","keywords":["watermark detection","image processing","copyright protection","digital watermarking","media forensics"]},"chiragpandya7/insight_face_swap":{"description":null,"keywords":["face recognition","facial analysis","biometric identification","security systems","surveillance software"]},"asiryan/proteus-v0.2":{"description":"Proteus v0.2 Model (Text2Img, Img2Img and Inpainting)","keywords":["Text2Img","Img2Img","Inpainting","image generation","text-to-image synthesis","image-to-image translation","image inpainting"]},"fofr/txt2img":{"description":"Many models: RealVisXL, Juggernaut, Proteus, DreamShaper, etc.","keywords":["Image generation","text-to-image","AI art","visual storytelling","image synthesis","computer vision"]},"batouresearch/sdxl-outpainting-lora":{"description":"An improved outpainting model that supports LoRA urls. This model uses PatchMatch to improve the mask quality.","keywords":["outpainting","LoRA","PatchMatch","image processing","computer vision","machine learning","deep learning"]},"lebonze/museai":{"description":"I fed the beast my oil paintings, made in the south of France.","keywords":["art","oil paintings","south of France","MuseAI"]},"usamaehsan/instant-id":{"description":"fast instant-id","keywords":["instant-id","fast identification","real-time recognition","AI-powered labeling","machine learning models"]},"sakemin/musicgen-remixer":{"description":"Remix the music into another styles with MusicGen Chord","keywords":["music generation","remixing","chord recognition","music style transfer","audio processing","machine learning","MusicGen Chord"]},"lucataco/moondream1":{"description":"(Research only) Moondream1 is a vision language model that performs on par with models twice its size","keywords":["Moondream1","vision language model","research","computer vision","natural language processing","AI","machine learning."]},"lucataco/proteus-v0.2":{"description":"Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities.","keywords":["Proteus v0.2","MJ6","prompt understanding","stylistic capabilities","language model","AI","NLP"]},"jonasloos/sdxl-turbo-h-space-modification-model":{"description":"SDXL-Turbo H-Space Modification","keywords":["machine learning","H-Space","Modification","SDXL-Turbo"]},"jyoung105/moondream":{"description":"Tiny vision language model","keywords":["moonDream","tiny vision language model","computer vision","natural language processing","NLP","image captioning","visual question answering","VQA","image-text matching","multimodal fusion","visual grounding","robotics","autonomous vehicles","medical imaging","security surveillance."]},"harsh-dhillon/instant-id":{"description":"Zero-shot Identity-Preserving Generation in Seconds","keywords":["instant-id","zero-shot generation","identity-preserving","data augmentation","privacy-preserving","GANs","generative models","synthetic data","fake data","artificial intelligence"]},"spuuntries/borealis-10.7b-dpo-gguf":{"description":"Undi95's Borealis 10.7B Mistral DPO Finetune, GGUF Q5_K_M quantized by Undi95.","keywords":["borealis","undi95","mistral","dpo","finetune","ggu","q5_k_m","quantized","ml models","machine learning"]},"aaronbesson/profilepics":{"description":"Generate up to 4 profile pics with only one training image.","keywords":["profile pictures","profile image generator","one-shot learning","few-shot learning","image synthesis","computer vision","machine learning","deep learning"]},"grandlineai/instant-id-photorealistic":{"description":"InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Juggernaut-XL v8 as the base model to encourage photorealism","keywords":["photorealistic image generation","zero-shot identity preservation","Juggernaut-XL v8","InstantID"]},"grandlineai/instant-id-artistic":{"description":"InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Dreamshaper-XL as the base model to encourage artistic generations","keywords":["Zero-shot","Identity-Preserving","Generation","Seconds","Dreamshaper-XL","Artistic Generations"]},"nateraw/musicgen-songstarter-v0.1":{"description":"Generate song ideas!","keywords":["song generation","music composition","creative writing","lyrics","melody","chord progression","musical ideas","song starters"]},"cjwbw/depth-anything":{"description":"Highly practical solution for robust monocular depth estimation by training on a combination of 1.5M labeled images and 62M+ unlabeled images","keywords":["monocular depth estimation","robust depth estimation","labeled images","unlabeled images","practical solution"]},"smoosh-sh/clarity_wave":{"description":"AI powered speech denoising and enhancement","keywords":["Speech denoising","speech enhancement","AI powered audio processing","noise reduction","voice clarity","audio quality improvement."]},"lucataco/siglip":{"description":"SigLIP proposes to replace the loss function used in CLIP by a simple pairwise sigmoid loss","keywords":["Sigmoid loss","CLIP","machine learning","computer vision","natural language processing","image classification","object detection","language modeling."]},"lucataco/wizardcoder-33b-v1.1-gguf":{"description":"WizardCoder: Empowering Code Large Language Models with Evol-Instruct","keywords":["natural language processing","machine learning","language models","code generation","AI development","Evol-Instruct","WizardCoder"]},"llsean/cog-realvis-instant-id":{"description":"InstantID : Zero-shot Identity-Preserving Generation in Seconds","keywords":["Zero-shot","Identity-Preserving","Generation","Seconds","InstantID","Real-time","Image Synthesis","Deep Learning"]},"cjwbw/tokenflow":{"description":"Consistent Diffusion Features for Consistent Video Editing","keywords":["video editing","consistent diffusion features","tokenflow","computer vision","machine learning"]},"grandlineai/resemble-enhance":{"description":"AI-driven audio enhancement for your audio/video files, powered by Resemble AI","keywords":["Audio enhancement","AI-driven audio editing","noise reduction","voice clarity","Resemble AI"]},"lucataco/nebul.redmond":{"description":"Nebul.Redmond - Stable Diffusion SD XL Finetuned Model","keywords":["Stable Diffusion","SD XL","Finetuned Model","Nebul.Redmond"]},"tencentarc/photomaker-style":{"description":"Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version)","keywords":["photo editing","artistic style transfer","avatar creation","portrait stylization","photography","machine learning","AI-generated art"]},"pollinations/amt":{"description":"Video Smoother: AMT All-Pairs Multi-Field Transforms for Efficient Frame Interpolation","keywords":["video smoothing","frame interpolation","AMT","All-Pairs Multi-Field Transforms"]},"smoosh-sh/mythomax-l2-13b-gptq":{"description":"MythoMax-L2-13B-GPTQ from TheBloke","keywords":["Natural Language Processing","Text Classification","Sentiment Analysis","Named Entity Recognition","Question Answering","Generative Pre-trained Transformer","MythoMax"]},"technillogue/sdxl-nyacomp":{"description":null,"keywords":["Natural Language Processing","Text Classification","Sentiment Analysis","Named Entity Recognition","Part-of-Speech Tagging","Dependency Parsing"]},"sontungpytn/comfyui-lora-upscaler":{"description":null,"keywords":["ComfyUI","Lora","upscaler","image processing","computer vision","machine learning","deep learning","photo editing","image enhancement","picture improvement","AI-powered tools"]},"shefa/turbo-enigma":{"description":"SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com","keywords":["Turbo-Enigma","SDXL","text-to-image","Distribution Matching Distillation","zero-shot identity generation","AI vision board"]},"kcaverly/neuralbeagle14-7b-gguf":{"description":"NeuralBeagle14-7B is (probably) the best 7B model you can find!","keywords":["neural network","machine learning","7B model","NeuralBeagle14-7B","AI","deep learning","natural language processing","text classification","sentiment analysis","spam detection","chatbots","virtual assistants"]},"voku682/video_style_transfer":{"description":null,"keywords":["video style transfer","deep learning","computer vision","image processing","video editing","special effects","video enhancement"]},"tomasmcm/sensei-7b-v1":{"description":"Source: SciPhi/Sensei-7B-V1 ‚ú¶ Quant: TheBloke/Sensei-7B-V1-AWQ ‚ú¶ Sensei is specialized in performing RAG over detailed web search results","keywords":["RAG","web search","detailed search results","Sensei-7B-V1","SciPhi","TheBloke","AWQ"]},"tomasmcm/whiterabbitneo-13b":{"description":"Source: WhiteRabbitNeo/WhiteRabbitNeo-13B-v1 ‚ú¶ TheBloke/WhiteRabbitNeo-13B-AWQ ‚ú¶ WhiteRabbitNeo is a model series that can be used for offensive and defensive cybersecurity","keywords":["WhiteRabbitNeo","cybersecurity","offensive cybersecurity","defensive cybersecurity"]},"mbukerepo/photomaker":{"description":"PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","keywords":["photomanipulation","photo editing","realistic images","human photos","stacked ID embedding","customization","AI-powered tools"]},"tencentarc/photomaker":{"description":"Create photos, paintings and avatars for anyone in any style within seconds.","keywords":["photo editing","art generation","avatar creation","style transfer","photography","painting","digital art","portrait creation","image manipulation"]},"konieshadow/fooocus-api-anime":{"description":"Third party Fooocus replicate model with preset 'anime'","keywords":["Fooocus","API","anime","third-party model","replicate","preset"]},"konieshadow/fooocus-api-realistic":{"description":"Third party Fooocus replicate model with preset 'realistic'","keywords":["Fooocus","API","realistic","third-party","replicate","model","preset"]},"konieshadow/fooocus-api":{"description":"Third party Fooocus replicate model","keywords":["fooocus-api","third party model replication","Fooocus integration","machine learning","API"]},"lucataco/whisperspeech-small":{"description":"An Open Source text-to-speech system built by inverting Whisper","keywords":["text-to-speech","TTS","speech synthesis","voice synthesis","Open Source","Whisper","whisperpeech-small"]},"usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5":{"description":"Updated -> Realistic_Vision_V6.0_B1 || Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter","keywords":["Realistic Vision","Inpainting","multi-controlnet","single-controlnet","ip-adapter","face recognition","object detection"]},"zsxkib/moore-animateanyone":{"description":"Unofficial Re-Trained AnimateAnyone (Image + DWPose Video ‚Üí Animated Video of Image)","keywords":["animated video","image animation","DWPose video","animation software","machine learning","deep learning","computer vision"]},"dhanushreddy291/arthemy-comics":{"description":null,"keywords":["arthemy-comics","art","comics","illustration","design","visual arts","graphics","cartoons"]},"adirik/realvisxl-v3.0-turbo":{"description":"Photorealism with RealVisXL V3.0 Turbo based on SDXL","keywords":["photorealism","RealVisXL V3.0 Turbo","SDXL","machine learning","computer vision","image processing","visual effects","graphics","gaming","simulation","rendering","animation","video production"]},"adirik/imagedream":{"description":"Image-Prompt Multi-view Diffusion for 3D Generation","keywords":["Computer vision","machine learning","3D generation","image processing","diffusion models","multi-view imaging."]},"smoosh-sh/baby-mystic":{"description":"Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent","keywords":["baby-mystic","Realistic Vision v5.1","image conjuring","potential baby","single photo","parent","baby prediction","family resemblance","genetic inheritance","facial features","machine learning","AI","computer vision"]},"alexgenovese/custom-endpoint":{"description":"Fooocus API based endpoint","keywords":["custom-endpoint","Fooocus API","endpoint development","API integration","machine learning models","customized solutions"]},"lucataco/magnet":{"description":"MAGNeT: Masked Audio Generation using a Single Non-Autoregressive Transformer","keywords":["Audio generation","music generation","audio synthesis","machine learning","transformer models","non-autoregressive models","masked audio generation"]},"dhanushreddy291/forge-saga-landscape":{"description":"ForgeSaga Landscape","keywords":["Landscape generation","terrain rendering","scenery creation","outdoor environments","video games","virtual reality","computer graphics."]},"dhanushreddy291/manmaru-mix-v3":{"description":"Manmaru mix v3.0","keywords":["Image classification","object detection","image segmentation","facial recognition","deep learning","computer vision"]},"yaeljiao/sdxl-emoji":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the ML model \"sdxl-emoji\":\n\nEmoji recognition","Emoji classification","Text analysis","Natural Language Processing","Machine Learning","Image processing"]},"tomasmcm/digital-socrates-13b":{"description":"Source: allenai/digital-socrates-13b ‚ú¶ Quant: TheBloke/digital-socrates-13B-AWQ ‚ú¶ Digital Socrates is an open-source, automatic explanation-critiquing model","keywords":["Digital Socrates","open-source","automatic explanation-critiquing model","AI","machine learning","natural language processing","NLP","text analysis","sentiment analysis","topic modeling","information retrieval","question answering","dialogue systems","conversational AI.\n\nHere's a comma separated list of search engine keywords:\n\ndigital-socrates-13b","allenai","TheBloke","digital-socrates-13B-AWQ","open-source","automatic explanation-critiquing model","AI","machine learning","NLP","text analysis","sentiment analysis","topic modeling","information retrieval","question answering","dialogue systems","conversational AI."]},"tomasmcm/towerinstruct-7b-v0.1":{"description":"Source: Unbabel/TowerInstruct-7B-v0.1 ‚ú¶ Quant: TheBloke/TowerInstruct-7B-v0.1-AWQ ‚ú¶ This model is trained to handle several translation-related tasks, such as general machine translation, gramatical error correction, and paraphrase generation","keywords":["Machine translation","grammatical error correction","paraphrase generation","natural language processing","text analysis","language modeling."]},"csslc/ccsr":{"description":"Improving the Stability of Diffusion Models for Content Consistent Super-Resolution","keywords":["Content Consistent Super-Resolution","Diffusion Models","Image Super-Resolution","Stability Improvement"]},"lucataco/proteus-v0.1":{"description":"ProteusV0.1 uses OpenDalleV1.1 as a base and further refines prompt adherence and stylistic capabilities to a measurable degree","keywords":["OpenDalleV1.1","ProteusV0.1","prompt adherence","stylistic capabilities","measurable degree"]},"batouresearch/sdxl-improved-refiner":{"description":"Great image quality, good old SDXL with a new and improved Tile refiner.","keywords":["Image quality","SDXL","Tile refiner","machine learning","computer vision"]},"cjwbw/video-retalking":{"description":"Audio-based Lip Synchronization for Talking Head Video","keywords":["video retalking","audio-based lip synchronization","talking head video","video editing","post-production","filmmaking","television production","virtual reality","augmented reality","3D animation","game development","video conferencing","live streaming","AV sync","audio visual sync","lip sync","speech synthesis"]},"dhanushreddy291/sdvn10-anime":{"description":"SDVN10-Anime","keywords":["anime","manga","cartoon","animation","japanese","culture","entertainment","art","design"]},"gustavo-kuze/sdxl-mate":{"description":null,"keywords":["sdxl-mate","machine learning","ML models","model training","data science","predictive analytics"]},"bluematter/sdxl-bluejeans":{"description":"SDXL Trained on blue jeans","keywords":["blue jeans","fashion","style","clothing","image classification","deep learning","SDXL"]},"ness-ai/akabane-all-02":{"description":"Ëµ§ÁæΩÂÖ®Âüü„ÅÆ„É¢„Éá„É´„Åß„ÅôÔºÅÊúÄÊñ∞Áâà„Å™„ÅÆ„Åß„Åì„Å°„Çâ„Çí„Åä‰Ωø„ÅÑ„Åè„Å†„Åï„ÅÑÔºÅ","keywords":["Akabane","all-round model","latest version","multi-purpose","versatile","Japanese."]},"catio-apps/photoaistudio-generate":{"description":"https://www.photoaistudio.com. Take a picture of your face and instantly get any profile picture you want. Only 1 photo, no training needed.","keywords":["Face recognition","profile picture generator","photo editing","AI-powered editing","image processing"]},"kevin-coyle/big-medium-images":{"description":"Generates Images in the Big Medium Style","keywords":["big-medium-images","image generation","artistic images","stylish images","big medium style","machine learning models","AI-generated images"]},"sparkdoaz/www":{"description":null,"keywords":["web search","internet searching","online research","search engine optimization","SEO","search marketing","keyword research"]},"erium/whisperx":{"description":"Automatic Speech Recognition with Word-level Timestamps & Diarization","keywords":["Speech recognition","automatic speech recognition","word-level timestamps","diarization","voice to text","audio transcription","speech to text","voice recognition","whisperx"]},"piddnad/ddcolor":{"description":"Towards Photo-Realistic Image Colorization via Dual Decoders","keywords":["Image colorization","photo-realistic colorization","dual decoders","computer vision","machine learning","deep learning"]},"tomasmcm/neuronovo-7b-v0.3":{"description":"Source: Neuronovo/neuronovo-7B-v0.3 ‚ú¶ Quant: TheBloke/neuronovo-7B-v0.3-AWQ ‚ú¶ Neuronovo/neuronovo-7B-v0.3 model represents an advanced and fine-tuned version of a large language model, initially based on CultriX/MistralTrix-v1.","keywords":["Neuronovo-7B-v0.3","TheBloke","neuronovo-7B-v0.3-AWQ","CultriX","MistralTrix-v1","large language model","advanced","fine-tuned"]},"catio-apps/cog-photostudio-ip_adapter_face-cyberrealistic":{"description":null,"keywords":["cyberrealistic face","photo studio software","IP adapter","facial recognition","AI-powered photography","virtual try-on","augmented reality"]},"ieit-yuan/yuan2.0-2b":{"description":"Yuan2.0 is a new generation LLM developed by IEIT System, enhanced the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects.","keywords":["Semantic understanding","mathematical reasoning","code comprehension","knowledge modeling","natural language processing","artificial intelligence","machine learning."]},"cswry/seesr":{"description":"SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution","keywords":["Image super-resolution","real-world image processing","semantics-aware image enhancement","deep learning models","computer vision"]},"lucataco/pheme":{"description":"Pheme generates a variety of conversational voices in 16 kHz for phone-call applications","keywords":["conversational ai","phone-call ai","voice generation","16 kHz audio","chatbots","virtual assistants"]},"farbodmehr/fcm4":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the FCM4 model:\n\n\"FCM4","Flow Cytometry","Cell Analysis","Cancer Research","Immunophenotyping","Cell Sorting","Biomarker Detection","High-Throughput Analysis","Single-Cell Analysis","Multi-Parametric Analysis\""]},"cuuupid/sdxl-meow":{"description":"make meow emojis!","keywords":["emoji","meow","cat","animal","fun","social media","chat","messaging","stickers","icons","emoticon"]},"farbodmehr/fcm3":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the FCM3 model:\n\nFcm3","Flow cytometry","Cell analysis","Cancer research","Immunophenotyping","Single-cell analysis","Protein expression","Cell surface markers","Immune cell characterization."]},"speshiou/majicmix-realistic-sd-webui":{"description":"Utilize the capabilities of SD WebUI, including Hires. fix and plenty of extensions (e.g. ADetailer)","keywords":["majicmix-realistic-sd-webui","SD WebUI","Hires. fix","ADetailer","extensions","web development","frontend design","user interface","UI/UX","realistic designs","modern web applications","customizable templates"]},"beautyyuyanli/multilingual-e5-large":{"description":"multilingual-e5-large: A multi-language text embedding model","keywords":["multilingual","text embedding","language model","natural language processing","machine learning","NLP","ML","e5-large"]},"beautyyuyanli/multilingual-e5-base":{"description":"multilingual-e5-base: A multi-language text embedding model","keywords":["multilingual-e5-base","multi-language text embedding model","natural language processing","machine learning","NLP","ML","language modeling","text analysis","sentiment analysis","topic modeling","named entity recognition","part-of-speech tagging","dependency parsing"]},"beautyyuyanli/multilingual-e5-small":{"description":"multilingual-e5-small: A multi-language text embedding model","keywords":["multilingual","text embedding","language model","machine learning","natural language processing","NLP","text analysis","sentiment analysis","topic modeling","document classification","information retrieval"]},"farbodmehr/fcm2":{"description":null,"keywords":["FCM2","Flow Cytometry","Cell Analysis","Machine Learning","Deep Learning"]},"zsxkib/trocr-base-handwritten":{"description":"üñãÔ∏è‚û°Ô∏èüì±Converts handwritten text images into digital text","keywords":["Handwriting recognition","text conversion","digitalization","document scanning","optical character recognition","OCR","handwritten text","image processing."]},"vidalfer/game-music-generator":{"description":"Gerador de m√∫sica para games condicionado a emo√ß√£o feito para a disciplina de Resid√™ncia em IA do Bacharelado em Intelig√™ncia Artificial-UFG","keywords":["Game music generator","AI music composition","emotional music generation","game soundtrack creation","resid√™ncia em IA","UFG."]},"dhanushreddy291/amused-text-to-image":{"description":"Amused is a lightweight text to image model based off of the muse architecture. Amused is particularly useful in applications that require a lightweight and fast model such as generating many images quickly at once.","keywords":["Text-to-image","lightweight model","fast model","image generation","Muse architecture","Amused"]},"farbodmehr/fcm1":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the FCM1 model:\n\nFcm1","Flow cytometry","Cell sorting","Cancer research","Immunology","Infection diseases","Immune system monitoring","High-throughput analysis."]},"fofr/latent-consistency-model":{"description":"Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet","keywords":["latent-consistency-model","img2img","large batching","canny controlnet","super-fast image processing","machine learning","computer vision"]},"fofr/sdxl-energy-drink":{"description":"SDXL fine-tuned on energy drink designs","keywords":["Energy drink","beverage design","packaging design","branding","marketing","product development"]},"alexgenovese/train-sdxl-lora":{"description":"Train SDXL 1.0 with LoRA | mixed precision bf16 and save precision fp16","keywords":["Train SDXL","LoRA","mixed precision","bf16","fp16","deep learning","machine learning","neural networks","model training","inference","optimization."]},"organisciak/ocsai-llama2-7b":{"description":null,"keywords":["computer vision","image classification","object detection","scene understanding","llama2","ocsai"]},"replicatemodel/swinir_t4":{"description":"Cheaper model SwinIR: Image Restoration Using Swin Transformer (analogue of the popular model: jingyunliang/swinir)","keywords":["Image restoration","Swin Transformer","jingyunliang","swinir"]},"kcaverly/nous-capybara-34b-gguf":{"description":"A SOTA Nous Research finetune of 200k Yi-34B fine tuned on the Capybara dataset.","keywords":["Nous Research","finetune","Yi-34B","Capybara dataset","SOTA","machine learning","deep learning","natural language processing","text classification","sentiment analysis."]},"fofr/sdxl-fresh-ink":{"description":"SDXL fine-tuned on photos of freshly inked tattoos","keywords":["tattoo recognition","image classification","fine-tuning","deep learning","computer vision"]},"fofr/toolkit":{"description":"Video toolkit ‚Äì convert, make GIFs, extract audio","keywords":["video conversion","GIF creation","audio extraction","video editing","multimedia toolkit"]},"gauravk95/sadtalker-video":{"description":"Make your video talk anything","keywords":["video","talk","anything","sadtalker-video"]},"appstanepro/med_mllama_7b":{"description":"A Text to text generation model that can help with Stress,Anxiety and Meditation related issue.","keywords":["Stress","Anxiety","Meditation","Text to text generation","Mental health","Mindfulness","Wellness"]},"cjwbw/diffmorpher":{"description":"Diffusion Models for Image Morphing","keywords":["image morphing","diffusion models","computer vision","image processing","machine learning"]},"meta/codellama-34b-instruct":{"description":"A 34 billion parameter Llama tuned for coding and conversation","keywords":["Certainly! Here's a list of potential search engine keywords for the \"codellama-34b-instruct\" model:\n\nCoding","conversation","Llama","language model","chatbot","dialogue system","natural language processing","AI","machine learning","instructional design","educational technology","e-learning."]},"meta/codellama-13b-instruct":{"description":"A 13 billion parameter Llama tuned for coding and conversation","keywords":["Coding","conversation","Llama","language model","AI","chatbots","natural language processing","machine learning","instructional design.\n\nKeywords: codellama-13b-instruct","coding","conversation","Llama","language model","AI","chatbots","NLP","machine learning","instructional design"]},"meta/codellama-7b-instruct":{"description":"A 7 billion parameter Llama tuned for coding and conversation","keywords":["Coding","conversation","Llama","language model","AI","machine learning","natural language processing","chatbots","virtual assistants","code generation","programming assistance."]},"meta/codellama-34b-python":{"description":"A 34 billion parameter Llama tuned for coding with Python","keywords":["Python","coding","Llama","language model","AI","machine learning","natural language processing","code generation","text classification","sentiment analysis."]},"meta/codellama-13b-python":{"description":"A 13 billion parameter Llama tuned for coding with Python","keywords":["Certainly! Here's a list of search engine keywords that could be relevant for the \"codellama-13b-python\" model:\n\nPython","coding","Llama","natural language processing","NLP","machine learning","ML","deep learning","neural networks","computer science","programming","software development."]},"meta/codellama-7b-python":{"description":"A 7 billion parameter Llama tuned for coding with Python","keywords":["Python","coding","Llama","machine learning","natural language processing","text generation","code completion","programming assistant"]},"meta/codellama-34b":{"description":"A 34 billion parameter Llama tuned for coding and conversation","keywords":["Certainly! Based on the given title and description","here's a list of search engine keywords that may be relevant for the codellama-34b model:\n\nCoding","conversation","Llama","tuned","34 billion parameters","language model","chatbot","dialogue system","natural language processing","NLP","AI","artificial intelligence."]},"meta/codellama-13b":{"description":"A 13 billion parameter Llama tuned for code completion","keywords":["Code completion","Llama model","natural language processing","machine learning","software development","coding assistance.\n\nKeywords: codellama-13b","code completion","Llama model","natural language processing","machine learning","software development","coding assistance"]},"meta/codellama-7b":{"description":"A 7 billion parameter Llama tuned for coding and conversation","keywords":["Llama","coding","conversation","natural language processing","chatbots","AI assistants","code generation","programming","software development."]},"farbodmehr/instagram2":{"description":null,"keywords":["Hashtag classification","sentiment analysis","image recognition","object detection","facial recognition."]},"lucataco/pasd-magnify":{"description":"(Academic and Non-commercial use only) Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization","keywords":["Image super-resolution","personalized stylization","pixel-aware stable diffusion","realistic image enhancement","academic use","non-commercial use."]},"nateraw/axolotl-llama-2-7b-english-to-hinglish":{"description":null,"keywords":["English-to-Hinglish","language translation","machine learning","natural language processing","text classification","sentiment analysis."]},"fameengine/fame-lob-realvisxl-v20":{"description":"Lob RealVis XL","keywords":["Image recognition","object detection","facial recognition","surveillance","security systems"]},"visoar/cat-xiaobai":{"description":"My Cat Xiaobai","keywords":["cat-xiaobai","my cat xiaobai","cat recognition","pet recognition","animal behavior analysis","machine learning for pets"]},"turian/insanely-fast-whisper-with-video":{"description":"whisper-large-v3, incredibly fast, with video transcription","keywords":["Fast whispering","large language model","video transcription","speech recognition"]},"cjwbw/dreamtalk":{"description":"RESEARCH/NON-COMMERCIAL USE ONLY: diffusion-based audio-driven expressive talking head generation","keywords":["talking head generation","audio-driven animation","expressive face synthesis","diffusion models","research use","non-commercial use"]},"georgedavila/sdxl-bling":{"description":"SDXL LoRA finetuned on diamond watches","keywords":["diamond watches","LoRA","SDXL","finetuning","machine learning","models"]},"georgedavila/sdxl-vermeer":{"description":"SDXL LoRA finetuned on Vermeer paintings","keywords":["LoRa","SDXL","Vermeer paintings","art analysis","image classification","machine learning","deep learning."]},"lucataco/sdxl-deepcache":{"description":"SDXL using DeepCache","keywords":["SDXL","DeepCache","machine learning","model training","data acceleration","neural networks","computer vision","natural language processing","recommendation systems"]},"hyuse202/sef":{"description":"Chest X ray","keywords":["Chest X-ray","Medical Imaging","Healthcare","Radiology","Diagnosis","Disease Detection"]},"vkolagotla/bapubomma_ai":{"description":"A LoRA fine tuned version of SDXL trained on late legendary Indian artist Bapu's art work","keywords":["Bapu","art","LoRA","SDXL","fine-tuned","Indian artist","late legendary artist","art work"]},"genkernel/headshot-public":{"description":"Just an experiment. Nothing new here.","keywords":["headshot","public","experiment","nothing new"]},"cjwbw/openvoice":{"description":"NON-COMMERCIAL USE ONLY: Versatile Instant Voice Cloning","keywords":["Instant voice cloning","voice cloning software","non-commercial use","openvoice"]},"yelboudouri/pixelpie":{"description":"Upscale pixel art with Stable Diffusion! ü•ß‚ú®","keywords":["pixel art","upscale","stable diffusion","image processing","machine learning","artistic effects"]},"ali-vilab/anydoor":{"description":"Anydoor: zero-shot object-level image customization","keywords":["zero-shot image customization","object-level image editing","image manipulation","photo editing software"]},"fofr/realvisxl-v3-multi-controlnet-lora":{"description":"RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting","keywords":["RealVisXl V3","multi-controlnet","lora loading","img2img","inpainting","computer vision","machine learning","deep learning","image processing","image enhancement","image restoration","image manipulation"]},"tomasmcm/llamaguard-7b":{"description":"Source: llamas-community/LlamaGuard-7b ‚ú¶ Quant: TheBloke/LlamaGuard-7B-AWQ ‚ú¶ Llama-Guard is a 7B parameter Llama 2-based input-output safeguard model","keywords":["LlamaGuard","7B parameter","Llama 2-based","input-output safeguard","model","ML","machine learning"]},"tomasmcm/pandalyst-7b-v1.2":{"description":"Source: pipizhao/Pandalyst-7B-V1.2 ‚ú¶ Quant: TheBloke/Pandalyst-7B-v1.2-AWQ ‚ú¶ Pandalyst: A large language model for mastering data analysis using pandas","keywords":["Pandalyst-7B-V1.2","TheBloke","pandas","data analysis","machine learning","natural language processing"]},"hamelsmu/honeycomb":{"description":"Honeycomb NLQ Generator","keywords":["Natural Language Query","Generative Model","Honeycomb","NLQG."]},"ali-vilab/i2vgen-xl":{"description":"RESEARCH/NON-COMMERCIAL USE ONLY: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models","keywords":["Image-to-video synthesis","cascaded diffusion models","high-quality video generation","research use","non-commercial use."]},"anotherjesse/fastai-bird":{"description":"fastai lesson 1 - bird or forest","keywords":["bird","forest","fastai","lesson 1","image classification","machine learning"]},"lucataco/tinyllama-1.1b-chat-v1.0":{"description":"This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T","keywords":["Chatbot","conversational AI","natural language processing","NLP","text-based interface","virtual assistant","customer service","support agent","chat model","TinyLlama","finetuned model","intermediate step","1431k","3T."]},"nvlabs/parakeet-rnnt-1.1b":{"description":"üó£Ô∏è Nvidia + Suno.ai's speech-to-text conversion with high accuracy and efficiency üìù","keywords":["Speech-to-text","conversion","high accuracy","efficiency","Nvidia","Suno.ai"]},"archievilliers/sdxl-picasso":{"description":"An SDXL fine-tune based on Picasso's work","keywords":["SDXL","Picasso","art","painting","fine-tune","machine learning","AI","deep learning","image generation","creative AI","artistic AI."]},"georgedavila/sdxl-basquiat":{"description":"SDXL LoRA finetuned on Basquiat Paintings","keywords":["Basquiat","paintings","art","LoRA","SDXL","machine learning","AI","deep learning","image classification","art analysis","art recognition","painting identification."]},"arusterholz-edu/bioshock":{"description":null,"keywords":["BioShock","first-person shooter","underwater city","dystopian society","genetic engineering","plasmids","gene tonics","Big Daddies","Little Sisters","Rapture","ADAM","EVE","Andrew Ryan","Objectivism."]},"cudanexus/nougat":{"description":"Nougat: Neural Optical Understanding for Academic Documents","keywords":["Neural networks","machine learning","academic documents","text analysis","document understanding","natural language processing.\n\nHere is a comma-separated list of search engine keywords for the given title and description:\n\nNeural networks","Machine Learning","Academic Documents","Text Analysis","Document Understanding","Natural Language Processing"]},"matsuitran/sdxl-anime-schoolboy":{"description":"Stable Diffusion XL fine-tunned in the theme of Anime Schoolboy","keywords":["Anime","schoolboy","stable diffusion XL","fine-tuned","ML models"]},"sakemin/audiosr-long-audio":{"description":"Versatile Audio Super-resolution at Scale which upsamples audio files to 48khz. Longer audio input is possible with this model","keywords":["Audio super-resolution","audio upsampling","48khz","long audio input"]},"cudanexus/detic":{"description":"Detecting Twenty-thousand Classes using Image-level Supervision","keywords":["object detection","image classification","supervised learning","computer vision","deep learning","convolutional neural networks","image recognition","classifying images","image-level supervision."]},"matsuitran/sdxl-anime-schoolgirl":{"description":"Stable Diffusion XL fine-tunned in the theme of Anime Schoolgirl","keywords":["sdxl-anime-schoolgirl","stable diffusion xl","anime","schoolgirl","fine-tuned","themed models","generative art","ai generated content"]},"tomasmcm/tinyllama-1.1b-chat-v1.0":{"description":"Source: TinyLlama/TinyLlama-1.1B-Chat-v1.0 ‚ú¶ Quant: TheBloke/TinyLlama-1.1B-Chat-v1.0-AWQ ‚ú¶ The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens.","keywords":["TinyLlama","chatbot","conversational AI","natural language processing","NLP","machine learning","pre-trained model","1.1B parameters","tokenized data","open source","TheBloke","AWQ."]},"georgedavila/ay-chihuahua-sdxl-lora":{"description":"SDXL LoRA I trained on chihuahua images","keywords":["Chihuahua","SDXL","LoRA","image recognition","dog breeds","animal images","pet photography"]},"sakemin/pytsmod":{"description":"PyTSMod is an open-source library for Time-Scale Modification(eg. time-stretching) algorithms, by Sangeon Yong at MAC Lab, KAIST.","keywords":["Time-Scale Modification","time-stretching","audio processing","speech processing","signal processing","machine learning","PyTSMod","Sangeon Yong","MAC Lab","KAIST."]},"vigourjiang/test_20240103":{"description":null,"keywords":["Testing","Quality Assurance","Model Evaluation"]},"georgedavila/bart-large-mnli-classifier":{"description":"Zero-shot classifier which classifies text into categories of your choosing. Returns a dictionary of the most likely class and all class likelihoods.","keywords":["bart-large-mnli-classifier","zero-shot classifier","text classification","category classification","likelihood estimation"]},"nateraw/nous-hermes-2-solar-10.7b":{"description":"Nous Hermes 2 - SOLAR 10.7B is the flagship Nous Research model on the SOLAR 10.7B base model..","keywords":["Nous Hermes 2","SOLAR 10.7B","flagship model","Nous Research","base model"]},"kcaverly/nous-hermes-2-solar-10.7b-gguf":{"description":"Nous Hermes 2 - SOLAR 10.7B is the flagship Nous Research model on the SOLAR 10.7B base model.","keywords":["Nous Hermes 2","SOLAR 10.7B","Nous Research","flagship model","AI","machine learning","deep learning","natural language processing","computer vision","image recognition","speech recognition","predictive analytics","data analysis","business intelligence","decision making","automation","robotics","healthcare","finance","banking","retail","marketing","advertising","transportation","logistics","supply chain management","cybersecurity","fraud detection","risk assessment","compliance","legal","regulatory","medical imaging","drug discovery","climate prediction","environmental monitoring","energy management","smart cities","IoT","autonomous vehicles","robotics","manufacturing","quality control","inventory management","customer service","chatbots","virtual assistants"]},"nqvinh/sdxl-heroestd":{"description":null,"keywords":["Sure","here's a list of potential search engine keywords for the ML model \"sdxl-heroestd\":\n\n* Hero Estimation\n* Sdxl Model\n* Time Series Forecasting\n* Financial Forecasting\n* Stock Price Prediction\n* Trading Signals\n* Investment Strategies\n* Portfolio Optimization\n* Risk Management\n* Algorithmic Trading\n* Quantitative Finance\n* Machine Learning in Finance"]},"open-mmlab/pia":{"description":"Personalized Image Animator","keywords":["Image animation","personalized content","dynamic images","animations","image editing software."]},"tomasmcm/docsgpt-7b-mistral":{"description":"Source: Arc53/docsgpt-7b-mistral ‚ú¶ Quant: TheBloke/docsgpt-7B-mistral-AWQ ‚ú¶ DocsGPT is optimized for Documentation (RAG), fine-tuned for providing answers that are based on context","keywords":["Documentation","RAG","context-based answers","fine-tuned","optimization"]},"anotherjesse/llava-lies":{"description":"LLaVA injecting randomness into the image","keywords":["computer vision","image processing","machine learning","randomness injection","image manipulation","deep learning","generative models","GANs."]},"alexgenovese/upscaler":{"description":"GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration","keywords":["face restoration","image upscaling","GFPGAN","practical algorithms","real-world applications"]},"batouresearch/open-dalle-1.1-lora":{"description":"Better than SDXL at both prompt adherence and image quality, by dataautogpt3","keywords":["open-dalle-1.1-lora","prompt adherence","image quality","dataautogpt3","SDXL"]},"fictions-ai/autocaption":{"description":"Automatically add captions to a video","keywords":["video captioning","automated subtitles","accessibility tools","media annotation","video editing software"]},"bawgz/stable-dripfusion-2":{"description":null,"keywords":["Stable Drip Fusion","Machine Learning","Artificial Intelligence","Automation","Data Analysis","Predictive Modeling","Decision Making","Natural Language Processing"]},"musicly-ai/singing_voice_conversion":{"description":"this is the replicate version of singing_voice_conversion from amphion","keywords":["singing voice conversion","audio processing","speech synthesis","voice morphing","vocal effects","music technology"]},"charlesmccarthy/animagine-xl":{"description":"Animagine XL 2.0 is an advanced latent text-to-image diffusion model designed to create high-resolution, detailed anime images.","keywords":["anime","high-resolution images","text-to-image synthesis","diffusion models","detailed images","latent text-to-image","animagine XL 2.0"]},"brewwh/cog-a1111-ui":{"description":"A collection of anime stable diffusion models with VAEs and LORAs.","keywords":["anime","stable diffusion models","VAEs","LORAs","machine learning","deep learning","computer vision"]},"zsxkib/patch-fusion":{"description":"Super High Quality Depth Maps üó∫Ô∏è: An End-to-End Tile-Based Framework üèóÔ∏è for High-Resolution Monocular Metric Depth Estimation üîçüìè","keywords":["depth estimation","monocular depth estimation","high-resolution depth maps","tile-based framework","end-to-end depth estimation","metric depth estimation"]},"lucataco/open-dalle-v1.1":{"description":"A unique fusion that showcases exceptional prompt adherence and semantic understanding, it seems to be a step above base SDXL and a step closer to DALLE-3 in terms of prompt comprehension","keywords":["Open-dalle-v1.1","prompt adherence","semantic understanding","SDXL","DALLE-3"]},"lucataco/diffusion-motion-transfer":{"description":"Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer","keywords":["zero-shot text-driven motion transfer","space-time diffusion features","video editing","animation","computer vision"]},"kcaverly/nous-hermes-2-yi-34b-gguf":{"description":"Nous Hermes 2 - Yi-34B is a state of the art Yi Fine-tune, fine tuned on GPT-4 generated synthetic data","keywords":["Nous Hermes 2","Yi-34B","GPT-4","synthetic data","fine-tune","ML model","natural language processing","text classification","sentiment analysis","named entity recognition","question answering","generative models","language generation"]},"thomasmol/whisper-diarization":{"description":"‚ö°Ô∏è Quick audio transcription | whisper v3 | speaker diarization | word level timestamps","keywords":["audio transcription","speech recognition","speaker diarization","word level timestamps","whisper v3"]},"charlesmccarthy/terminus-xl-otaku-v1":{"description":"Terminus XL Otaku is a latent diffusion model that uses zero-terminal SNR noise schedule and velocity prediction objective at training and inference time.","keywords":["terminus-xl-otaku-v1","latent diffusion model","zero-terminal SNR noise schedule","velocity prediction objective"]},"flyingteacups/custom-sdxl":{"description":"Inference SDXL with cog including multiple models in 1 instance support.","keywords":["Custom SDXL","Inference SDXL","cog","multiple models","instance support","machine learning","AI","deep learning","neural networks","natural language processing","computer vision","image recognition","predictive analytics."]},"usamaehsan/controlnet-x-majic-mix-realistic-x-ip-adapter":{"description":"works with inpainting and multi-controlnet + single-controlnet || ip-adapter + without ip adapter","keywords":["ControlNet","Inpainting","Multi-ControlNet","Single-ControlNet","IP Adapter","Realistic X."]},"cjwbw/faster-diffusion":{"description":"Rethinking the Role of UNet Encoder in Diffusion Models","keywords":["faster-diffusion","UNet encoder","diffusion models","image generation","image synthesis","machine learning","computer vision"]},"yan-ops/face_swap":{"description":null,"keywords":["face swapping","image manipulation","deepfake detection","facial recognition","photo editing"]},"charlesmccarthy/terminus-xl-gamma-v2":{"description":"Terminus XL Gamma is a new state-of-the-art latent diffusion model that uses zero-terminal SNR noise schedule and velocity prediction objective at training and inference time.","keywords":["terminus-xl-gamma-v2","latent diffusion model","zero-terminal SNR noise schedule","velocity prediction objective"]},"illscience/dreaminaudio":{"description":"Fine-tune of music gen with tracks from my record label Dream In Audio.","keywords":["music genre classification","audio fine-tuning","record label catalogue","Dream In Audio"]},"tomasmcm/sam-7b":{"description":"Source: SuperAGI/SAM ‚ú¶ Quant: TheBloke/SAM-AWQ ‚ú¶ SAM (Small Agentic Model), a 7B model that demonstrates impressive reasoning abilities despite its smaller size","keywords":["Small Agentic Model","SAM","SuperAGI","AWQ","TheBloke","reasoning abilities","ML models","AI","machine learning"]},"alekseycalvin/neurealhistory3":{"description":"RealvisXL3 fine-tuned on 300+ colorized 1850s-1940s photos","keywords":["neural network","machine learning","computer vision","image processing","historical photos","colorization","fine-tuning","RealvisXL3"]},"illscience/deephouse-maker":{"description":null,"keywords":["deep house","maker","music generation","audio synthesis","machine learning","neural networks"]},"mistralai/mistral-7b-instruct-v0.2":{"description":"The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1.","keywords":["Large Language Model","Mistral-7B-Instruct-v0.2","Improved Instruct Fine-Tuned","Natural Language Processing","NLP","Machine Learning","ML Models","Language Understanding","Text Analysis","Sentiment Analysis","Question Answering","Dialogue Systems","Chatbots","Conversational AI","Virtual Assistants"]},"mistralai/mistral-7b-instruct-v0.1":{"description":"An instruction-tuned 7 billion parameter language model from Mistral","keywords":["natural language processing","language model","instruction-tuned model","Mistral","mistral-7b-instruct-v0.1"]},"martintmv-git/emoji-me":{"description":"RealVisXL_V3.0, img-to-emoji","keywords":["emoji","emoticon","image to emoji","img-to-emoji","RealVisXL_V3.0"]},"mistralai/mistral-7b-v0.1":{"description":"A 7 billion parameter language model from Mistral.","keywords":["Mistral","language model","7 billion parameters","natural language processing","text classification","sentiment analysis","named entity recognition","question answering","machine learning","AI","chatbots","virtual assistants","customer service","language translation","text summarization."]},"batouresearch/high-resolution-controlnet-tile":{"description":"Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination.","keywords":["high-resolution-controlnet-tile","ControlNet 1.1 tile","high-quality upscales","image hallucination"]},"mistralai/mixtral-8x7b-instruct-v0.1":{"description":"The Mixtral-8x7B-instruct-v0.1 Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts tuned to be a helpful assistant.","keywords":["Large Language Model","Pretrained Generative Model","Sparse Mixture of Experts","Helpful Assistant","Natural Language Processing","Machine Learning","AI Assistant","Chatbot","Conversational AI","Text Generation","Language Understanding"]},"martintmv-git/realistic-emoji":{"description":"RealVisXL_V3.0, fine-tuned on Apple's emojis","keywords":["RealVisXL_V3.0","Apple emojis","fine-tuned models","realistic emoji generation","emoji creation","emoji-based communication","visual representation","machine learning"]},"fofr/sdxl-simpsons-characters":{"description":"SDXL fine-tuned on MJv6 Simpsons generated images","keywords":["Simpsons","SDXL","MJv6","generated images","fine-tuned","deep learning","machine learning","AI models"]},"fofr/sdxl-multi-controlnet-lora":{"description":"Multi-controlnet, lora loading, img2img, inpainting","keywords":["sdxl-multi-controlnet-lora","multi-controlnet","lora loading","img2img","inpainting","image-to-image translation","image synthesis","computer vision"]},"jd7h/luciddreamer":{"description":"High-Fidelity Text-to-3D Generation via Interval Score Matching","keywords":["Text-to-3D","Interval Score Matching","High-Fidelity Generation","Lucid Dreaming","3D Modeling","Computer Vision"]},"cloversid099/deepfake":{"description":"DeepFake AI","keywords":["deepfake","ai","machine learning","video manipulation","fake news","disinformation","image recognition","facial recognition"]},"replicate-internal/mixtral-8x7b-instruct-v0.1-pget":{"description":null,"keywords":["mixtral-8x7b-instruct-v0.1-pget","machine learning","ML models","instruct","v0.1","pget"]},"lucataco/singing_voice_conversion":{"description":"Amphion Singing Voice Conversion: DiffWaveNetSVC","keywords":["Singing voice conversion","audio processing","speech synthesis","vocal effects","music technology"]},"zelenioncode/custum_model_safetonsors":{"description":"DreamBooth safetensors model use RealVisXL","keywords":["Custom model","safety sensors","RealVisXL","object detection","tracking","autonomous systems","robotics","computer vision","machine learning.\n\nKeywords: custom model","safety sensors","RealVisXL","object detection","tracking","autonomous systems","robotics","computer vision","machine learning"]},"fofr/realvisxl-v3":{"description":"Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable","keywords":["photorealism","RealVisXL_V3.0","SDXL","trainable models","machine learning","computer vision"]},"sakemin/all-in-one-music-structure-analyzer":{"description":"Cog implementation of mir-aidj(Taejun Kim)'s 'All-In-One Music Structure Analyzer'","keywords":["music structure analysis","audio signal processing","music information retrieval","musical pattern recognition","music composition","music theory","machine learning","music analysis software"]},"ashesashes/ugly-sweater":{"description":"Ugly Sweaters: The only garment that screams \"Fashion? Never heard of it.\"","keywords":["Ugly sweaters","novelty sweaters","holiday sweaters","festive wear","fashion fail"]},"lucataco/ip-adapter-faceid":{"description":"(Research only) IP-Adapter-FaceID can generate various style images conditioned on a face with only text prompts","keywords":["Face recognition","image generation","text-to-image synthesis","style transfer","face manipulation","AI art","machine learning models."]},"annakaz/sdxl-inference":{"description":null,"keywords":["sdxl-inference","machine learning","inference","null"]},"remodela-ai/scaling-model-v1":{"description":null,"keywords":["Scaling","model","v1","null"]},"culturecloud/dreamshaper-xl-turbo":{"description":"DreamShaper is a general purpose SD model that aims at doing everything well, photos, art, anime, manga. It's designed to go against other general purpose models and pipelines like Midjourney and DALL-E.","keywords":["SD model","general purpose model","photo editing","art generation","anime creation","manga illustration","Midjourney","DALL-E."]},"batouresearch/dpo-sdxl-controlnet-lora":{"description":"DPO-SDXL Canny controlnet with LoRA support.","keywords":["object detection","semantic segmentation","Canny edge detection","control net","LoRA support"]},"magpai-app/cog-puppeteer":{"description":null,"keywords":["Certainly! Here is a list of potential search engine keywords for the \"cog-puppeteer\" model:\n\nMachine learning","AI","automation","robotics","computer vision","natural language processing","predictive analytics","decision making","autonomous systems","intelligent agents","cognitive computing."]}}